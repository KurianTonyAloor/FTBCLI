{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f84b526",
   "metadata": {},
   "source": [
    "# ðŸ§  Fine-Tune TinyLlama with QLoRA\n",
    "This notebook fine-tunes the `TinyLlama-1.1B-Chat-v1.0` model on CLI Q&A data using QLoRA with the PEFT library.\n",
    "Ensure `full_qa_pairs.json` is uploaded to the Colab working directory before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes==0.41.1\n",
    "!pip install -q transformers accelerate peft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload full_qa_pairs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load dataset\n",
    "with open('full_qa_pairs.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Format: 'Q: question\\nA: answer'\n",
    "formatted_data = [{'text': f\"Q: {item['question']}\\nA: {item['answer']}\"} for item in data]\n",
    "dataset = Dataset.from_list(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "model_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM'\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example['text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./lora-tinyllama',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy='epoch',\n",
    "    report_to='none'\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save adapter\n",
    "trainer.train()\n",
    "model.save_pretrained('./lora-tinyllama')\n",
    "tokenizer.save_pretrained('./lora-tinyllama')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
